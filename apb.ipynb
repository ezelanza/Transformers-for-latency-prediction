{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entendiendo el Informer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir los args\n",
    "args = dotdict()\n",
    "\n",
    "args.model = 'informer' # model of experiment, options: [informer, informerstack, informerlight(TBD)]\n",
    "\n",
    "args.data = 'train_norm' # data\n",
    "args.root_path = './Dataset/Train/' # root path of data file\n",
    "args.data_path = 'train_norm_full.csv' # data file\n",
    "args.features = 'MS' # forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate\n",
    "args.target = 'p95 deploy/frontend' # target feature in S or MS task\n",
    "args.freq = 't' # freq for time features encoding, options:[s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], you can also use more detailed freq like 15min or 3h\n",
    "args.checkpoints = './informer_checkpoints' # location of model checkpoints\n",
    "\n",
    "args.seq_len = 96 # input sequence length of Informer encoder\n",
    "args.label_len = 48 # start token length of Informer decoder\n",
    "args.pred_len = 24 # prediction sequence length\n",
    "# Informer decoder input: concat[start token series(label_len), zero padding series(pred_len)]\n",
    "\n",
    "args.enc_in = 60 # encoder input size\n",
    "args.dec_in = 60 # decoder input size\n",
    "args.c_out = 10 # output size\n",
    "args.factor = 5 # probsparse attn factor\n",
    "args.d_model = 512 # dimension of model\n",
    "args.n_heads = 8 # num of heads\n",
    "args.e_layers = 2 # num of encoder layers\n",
    "args.d_layers = 1 # num of decoder layers\n",
    "args.d_ff = 2048 # dimension of fcn in model\n",
    "args.dropout = 0.05 # dropout\n",
    "args.attn = 'prob' # attention used in encoder, options:[prob, full]\n",
    "args.embed = 'fixed' # time features encoding, options:[timeF, fixed, learned]\n",
    "args.activation = 'gelu' # activation\n",
    "args.distil = True # whether to use distilling in encoder\n",
    "args.output_attention = False # whether to output attention in ecoder\n",
    "args.mix = True\n",
    "args.padding = 0\n",
    "args.scale = False\n",
    "\n",
    "args.batch_size = 32 \n",
    "args.learning_rate = 0.0001\n",
    "args.loss = 'mse'\n",
    "args.lradj = 'type1'\n",
    "args.use_amp = False # whether to use automatic mixed precision training\n",
    "\n",
    "args.num_workers = 0\n",
    "args.itr = 1\n",
    "args.train_epochs = 6\n",
    "args.patience = 3\n",
    "args.des = 'exp'\n",
    "\n",
    "args.use_gpu = True if torch.cuda.is_available() else False\n",
    "args.gpu = 0\n",
    "\n",
    "args.use_multi_gpu = False\n",
    "args.devices = '0,1,2,3'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Primero arma el traindata\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('/Users/emlanza/Library/CloudStorage/OneDrive-UniversidadAustral/Facultad/Maestria Data Science AUSTRAL/Tesis/Transformers-for-latency-prediction/Informer/Informer2020')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(os.path.join(args.root_path,\n",
    "                                          args.data_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>p50 deploy/adservice</th>\n",
       "      <th>p50 deploy/cartservice</th>\n",
       "      <th>p50 deploy/checkoutservice</th>\n",
       "      <th>p50 deploy/currencyservice</th>\n",
       "      <th>p50 deploy/emailservice</th>\n",
       "      <th>p50 deploy/frontend</th>\n",
       "      <th>p50 deploy/loadgenerator</th>\n",
       "      <th>p50 deploy/paymentservice</th>\n",
       "      <th>p50 deploy/productcatalogservice</th>\n",
       "      <th>...</th>\n",
       "      <th>deploy/currencyservice</th>\n",
       "      <th>deploy/emailservice</th>\n",
       "      <th>deploy/frontend</th>\n",
       "      <th>deploy/loadgenerator</th>\n",
       "      <th>deploy/paymentservice</th>\n",
       "      <th>deploy/productcatalogservice</th>\n",
       "      <th>deploy/recommendationservice</th>\n",
       "      <th>deploy/redis-cart</th>\n",
       "      <th>deploy/shippingservice</th>\n",
       "      <th>p95 deploy/frontend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-10-07 09:18:00</td>\n",
       "      <td>13.460422</td>\n",
       "      <td>-1.643790</td>\n",
       "      <td>-0.057770</td>\n",
       "      <td>-0.217764</td>\n",
       "      <td>-1.146121</td>\n",
       "      <td>-0.346990</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>-0.644470</td>\n",
       "      <td>-0.522305</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000067</td>\n",
       "      <td>-2.081668e-17</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.001252</td>\n",
       "      <td>-2.081668e-17</td>\n",
       "      <td>4.805699</td>\n",
       "      <td>-0.535875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-10-07 09:18:05</td>\n",
       "      <td>10.031784</td>\n",
       "      <td>0.229134</td>\n",
       "      <td>-0.434722</td>\n",
       "      <td>-0.217764</td>\n",
       "      <td>-0.898530</td>\n",
       "      <td>-0.346990</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>-0.644470</td>\n",
       "      <td>-0.429260</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000067</td>\n",
       "      <td>-2.081668e-17</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.001252</td>\n",
       "      <td>-2.081668e-17</td>\n",
       "      <td>4.805699</td>\n",
       "      <td>-0.535875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-10-07 09:18:10</td>\n",
       "      <td>10.031784</td>\n",
       "      <td>0.229134</td>\n",
       "      <td>-0.434722</td>\n",
       "      <td>-0.228521</td>\n",
       "      <td>-0.898530</td>\n",
       "      <td>-0.393260</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>0.922269</td>\n",
       "      <td>-0.429260</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000067</td>\n",
       "      <td>-2.081668e-17</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.001252</td>\n",
       "      <td>-2.081668e-17</td>\n",
       "      <td>-0.005351</td>\n",
       "      <td>-0.623315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-10-07 09:18:15</td>\n",
       "      <td>8.460325</td>\n",
       "      <td>-0.890356</td>\n",
       "      <td>-0.010651</td>\n",
       "      <td>-0.228521</td>\n",
       "      <td>-0.452866</td>\n",
       "      <td>-0.393260</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>0.922269</td>\n",
       "      <td>-0.592773</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000067</td>\n",
       "      <td>-2.081668e-17</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.001252</td>\n",
       "      <td>-2.081668e-17</td>\n",
       "      <td>-0.005351</td>\n",
       "      <td>-0.623315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-10-07 09:18:20</td>\n",
       "      <td>8.460325</td>\n",
       "      <td>-0.890356</td>\n",
       "      <td>-0.010651</td>\n",
       "      <td>-0.325898</td>\n",
       "      <td>-0.452866</td>\n",
       "      <td>-0.392411</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>0.400022</td>\n",
       "      <td>-0.592773</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000067</td>\n",
       "      <td>-2.081668e-17</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.001252</td>\n",
       "      <td>-2.081668e-17</td>\n",
       "      <td>-0.005351</td>\n",
       "      <td>-0.237772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1800</th>\n",
       "      <td>2021-10-07 11:48:00</td>\n",
       "      <td>-0.254131</td>\n",
       "      <td>0.002309</td>\n",
       "      <td>-0.010651</td>\n",
       "      <td>-0.722205</td>\n",
       "      <td>0.587018</td>\n",
       "      <td>-0.532381</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>0.086675</td>\n",
       "      <td>-0.670068</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000067</td>\n",
       "      <td>-2.081668e-17</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-2.177623</td>\n",
       "      <td>-2.081668e-17</td>\n",
       "      <td>-0.005351</td>\n",
       "      <td>-0.463400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1801</th>\n",
       "      <td>2021-10-07 11:48:05</td>\n",
       "      <td>-0.254131</td>\n",
       "      <td>-0.166355</td>\n",
       "      <td>-0.434722</td>\n",
       "      <td>-0.722205</td>\n",
       "      <td>0.215631</td>\n",
       "      <td>-0.532381</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>0.086675</td>\n",
       "      <td>-0.586403</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000067</td>\n",
       "      <td>-2.081668e-17</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-2.177623</td>\n",
       "      <td>-2.081668e-17</td>\n",
       "      <td>-0.005351</td>\n",
       "      <td>-0.463400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1802</th>\n",
       "      <td>2021-10-07 11:48:10</td>\n",
       "      <td>-0.254131</td>\n",
       "      <td>-0.166355</td>\n",
       "      <td>-0.434722</td>\n",
       "      <td>0.248105</td>\n",
       "      <td>0.215631</td>\n",
       "      <td>-0.503038</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>-0.748919</td>\n",
       "      <td>-0.586403</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000067</td>\n",
       "      <td>-2.081668e-17</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.001252</td>\n",
       "      <td>-2.081668e-17</td>\n",
       "      <td>-0.005351</td>\n",
       "      <td>0.627135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1803</th>\n",
       "      <td>2021-10-07 11:48:15</td>\n",
       "      <td>0.031589</td>\n",
       "      <td>0.688184</td>\n",
       "      <td>0.554777</td>\n",
       "      <td>0.248105</td>\n",
       "      <td>-0.650939</td>\n",
       "      <td>-0.503038</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>-0.748919</td>\n",
       "      <td>-0.471991</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000067</td>\n",
       "      <td>-2.081668e-17</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.001252</td>\n",
       "      <td>-2.081668e-17</td>\n",
       "      <td>-0.005351</td>\n",
       "      <td>0.627135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1804</th>\n",
       "      <td>2021-10-07 11:48:20</td>\n",
       "      <td>0.031589</td>\n",
       "      <td>0.688184</td>\n",
       "      <td>0.554777</td>\n",
       "      <td>0.727939</td>\n",
       "      <td>-0.650939</td>\n",
       "      <td>-0.291437</td>\n",
       "      <td>1.110223e-16</td>\n",
       "      <td>-0.470388</td>\n",
       "      <td>-0.471991</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000067</td>\n",
       "      <td>-2.081668e-17</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>2.175554</td>\n",
       "      <td>-2.081668e-17</td>\n",
       "      <td>-0.005351</td>\n",
       "      <td>3.618416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1805 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     date  p50 deploy/adservice  p50 deploy/cartservice  \\\n",
       "0     2021-10-07 09:18:00             13.460422               -1.643790   \n",
       "1     2021-10-07 09:18:05             10.031784                0.229134   \n",
       "2     2021-10-07 09:18:10             10.031784                0.229134   \n",
       "3     2021-10-07 09:18:15              8.460325               -0.890356   \n",
       "4     2021-10-07 09:18:20              8.460325               -0.890356   \n",
       "...                   ...                   ...                     ...   \n",
       "1800  2021-10-07 11:48:00             -0.254131                0.002309   \n",
       "1801  2021-10-07 11:48:05             -0.254131               -0.166355   \n",
       "1802  2021-10-07 11:48:10             -0.254131               -0.166355   \n",
       "1803  2021-10-07 11:48:15              0.031589                0.688184   \n",
       "1804  2021-10-07 11:48:20              0.031589                0.688184   \n",
       "\n",
       "      p50 deploy/checkoutservice  p50 deploy/currencyservice  \\\n",
       "0                      -0.057770                   -0.217764   \n",
       "1                      -0.434722                   -0.217764   \n",
       "2                      -0.434722                   -0.228521   \n",
       "3                      -0.010651                   -0.228521   \n",
       "4                      -0.010651                   -0.325898   \n",
       "...                          ...                         ...   \n",
       "1800                   -0.010651                   -0.722205   \n",
       "1801                   -0.434722                   -0.722205   \n",
       "1802                   -0.434722                    0.248105   \n",
       "1803                    0.554777                    0.248105   \n",
       "1804                    0.554777                    0.727939   \n",
       "\n",
       "      p50 deploy/emailservice  p50 deploy/frontend  p50 deploy/loadgenerator  \\\n",
       "0                   -1.146121            -0.346990              1.110223e-16   \n",
       "1                   -0.898530            -0.346990              1.110223e-16   \n",
       "2                   -0.898530            -0.393260              1.110223e-16   \n",
       "3                   -0.452866            -0.393260              1.110223e-16   \n",
       "4                   -0.452866            -0.392411              1.110223e-16   \n",
       "...                       ...                  ...                       ...   \n",
       "1800                 0.587018            -0.532381              1.110223e-16   \n",
       "1801                 0.215631            -0.532381              1.110223e-16   \n",
       "1802                 0.215631            -0.503038              1.110223e-16   \n",
       "1803                -0.650939            -0.503038              1.110223e-16   \n",
       "1804                -0.650939            -0.291437              1.110223e-16   \n",
       "\n",
       "      p50 deploy/paymentservice  p50 deploy/productcatalogservice  ...  \\\n",
       "0                     -0.644470                         -0.522305  ...   \n",
       "1                     -0.644470                         -0.429260  ...   \n",
       "2                      0.922269                         -0.429260  ...   \n",
       "3                      0.922269                         -0.592773  ...   \n",
       "4                      0.400022                         -0.592773  ...   \n",
       "...                         ...                               ...  ...   \n",
       "1800                   0.086675                         -0.670068  ...   \n",
       "1801                   0.086675                         -0.586403  ...   \n",
       "1802                  -0.748919                         -0.586403  ...   \n",
       "1803                  -0.748919                         -0.471991  ...   \n",
       "1804                  -0.470388                         -0.471991  ...   \n",
       "\n",
       "      deploy/currencyservice  deploy/emailservice  deploy/frontend  \\\n",
       "0                  -0.000017            -0.000005        -0.000005   \n",
       "1                  -0.000017            -0.000005        -0.000005   \n",
       "2                  -0.000017            -0.000005        -0.000005   \n",
       "3                  -0.000017            -0.000005        -0.000005   \n",
       "4                  -0.000017            -0.000005        -0.000005   \n",
       "...                      ...                  ...              ...   \n",
       "1800               -0.000017            -0.000005        -0.000005   \n",
       "1801               -0.000017            -0.000005        -0.000005   \n",
       "1802               -0.000017            -0.000005        -0.000005   \n",
       "1803               -0.000017            -0.000005        -0.000005   \n",
       "1804               -0.000017            -0.000005        -0.000005   \n",
       "\n",
       "      deploy/loadgenerator  deploy/paymentservice  \\\n",
       "0                -0.000067          -2.081668e-17   \n",
       "1                -0.000067          -2.081668e-17   \n",
       "2                -0.000067          -2.081668e-17   \n",
       "3                -0.000067          -2.081668e-17   \n",
       "4                -0.000067          -2.081668e-17   \n",
       "...                    ...                    ...   \n",
       "1800             -0.000067          -2.081668e-17   \n",
       "1801             -0.000067          -2.081668e-17   \n",
       "1802             -0.000067          -2.081668e-17   \n",
       "1803             -0.000067          -2.081668e-17   \n",
       "1804             -0.000067          -2.081668e-17   \n",
       "\n",
       "      deploy/productcatalogservice  deploy/recommendationservice  \\\n",
       "0                        -0.000055                     -0.001252   \n",
       "1                        -0.000055                     -0.001252   \n",
       "2                        -0.000055                     -0.001252   \n",
       "3                        -0.000055                     -0.001252   \n",
       "4                        -0.000055                     -0.001252   \n",
       "...                            ...                           ...   \n",
       "1800                     -0.000055                     -2.177623   \n",
       "1801                     -0.000055                     -2.177623   \n",
       "1802                     -0.000055                     -0.001252   \n",
       "1803                     -0.000055                     -0.001252   \n",
       "1804                     -0.000055                      2.175554   \n",
       "\n",
       "      deploy/redis-cart  deploy/shippingservice  p95 deploy/frontend  \n",
       "0         -2.081668e-17                4.805699            -0.535875  \n",
       "1         -2.081668e-17                4.805699            -0.535875  \n",
       "2         -2.081668e-17               -0.005351            -0.623315  \n",
       "3         -2.081668e-17               -0.005351            -0.623315  \n",
       "4         -2.081668e-17               -0.005351            -0.237772  \n",
       "...                 ...                     ...                  ...  \n",
       "1800      -2.081668e-17               -0.005351            -0.463400  \n",
       "1801      -2.081668e-17               -0.005351            -0.463400  \n",
       "1802      -2.081668e-17               -0.005351             0.627135  \n",
       "1803      -2.081668e-17               -0.005351             0.627135  \n",
       "1804      -2.081668e-17               -0.005351             3.618416  \n",
       "\n",
       "[1805 rows x 61 columns]"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.data_loader import Dataset_Custom,Dataset_Pred\n",
    "from utils.tools import dotdict\n",
    "from exp.exp_informer import Exp_Informer\n",
    "from utils.timefeatures import time_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pandas.tseries import offsets\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definicion de argumentos\n",
    "timeenc=0\n",
    "flag='test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "Data = Dataset_Custom\n",
    "timeenc = 0 if args.embed!='timeF' else 1\n",
    "flag = 'train'; shuffle_flag = False; drop_last = True; batch_size = 1\n",
    "\n",
    "data_set = Data(\n",
    "            root_path=args.root_path,\n",
    "            data_path=args.data_path,\n",
    "            flag=flag,\n",
    "            size=[args.seq_len, args.label_len, args.pred_len],\n",
    "            features=args.features,\n",
    "            target=args.target,\n",
    "            inverse=args.inverse,\n",
    "            timeenc=timeenc,\n",
    "            freq=args.freq,\n",
    "            cols=args.cols\n",
    "        )\n",
    "data_loader = DataLoader(\n",
    "    data_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=shuffle_flag,\n",
    "    num_workers=args.num_workers,\n",
    "    drop_last=drop_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.39763364e+00,  2.40214129e-01, -4.28377773e-01, -2.21491876e-01,\n",
       "       -8.86168692e-01, -3.52054196e-01, -7.68083811e-01, -4.34242227e-01,\n",
       "        7.17525120e-01,  1.85467071e-01,  1.79053116e-01,  1.46643220e-01,\n",
       "       -3.67835180e-01, -7.31805468e-01, -1.31100546e-01, -3.03386031e-01,\n",
       "        9.83190882e-01, -1.73902966e-01, -3.81574712e-01, -3.30107466e-01,\n",
       "       -3.32954236e-01, -1.32440016e-01, -1.80196351e-01, -5.39782328e-01,\n",
       "       -7.13910675e-01, -3.14416091e-01, -2.94456656e-01, -5.85306187e-01,\n",
       "        9.73434108e-01, -1.38358969e-01, -1.92280906e-01, -5.64795317e-01,\n",
       "       -3.24069510e-01, -2.27310357e-01, -5.96856376e-01, -5.02661170e-01,\n",
       "       -2.16902910e-01, -6.27486143e-01, -2.15123637e-01, -5.34150667e-01,\n",
       "       -8.01818576e-05, -5.23852905e-01, -5.92189081e-01, -5.00851309e-01,\n",
       "       -4.74602432e-01, -5.21888083e-05, -5.15784022e-05, -1.00000000e+00,\n",
       "       -1.94948064e-05, -5.62766600e-06, -5.62766603e-06, -8.01818577e-05,\n",
       "       -5.09606634e-05, -1.81380069e-03,  4.36809261e+00, -5.15401549e-01])"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set.data_x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_nan(data_loader):\n",
    "    for batch_idx, batch in enumerate(data_loader):\n",
    "        # iterate over each tensor in the batch\n",
    "        for tensor in batch:\n",
    "            # check if the tensor contains NaN values\n",
    "            if torch.isnan(tensor).any():\n",
    "                print(f\"Found NaN values in batch {batch_idx}\")\n",
    "\n",
    "check_for_nan(data_loader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model step by step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, verbose=False, delta=0):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, val_loss, model, path):\n",
    "        score = -val_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, path)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model, path)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model, path):\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), path+'/'+'checkpoint.pth')\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, epoch, args):\n",
    "    # lr = args.learning_rate * (0.2 ** (epoch // 2))\n",
    "    if args.lradj=='type1':\n",
    "        lr_adjust = {epoch: args.learning_rate * (0.5 ** ((epoch-1) // 1))}\n",
    "    elif args.lradj=='type2':\n",
    "        lr_adjust = {\n",
    "            2: 5e-5, 4: 1e-5, 6: 5e-6, 8: 1e-6, \n",
    "            10: 5e-7, 15: 1e-7, 20: 5e-8\n",
    "        }\n",
    "    if epoch in lr_adjust.keys():\n",
    "        lr = lr_adjust[epoch]\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "        print('Updating learning rate to {}'.format(lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(args, flag):\n",
    "        #rgs = self.args\n",
    "\n",
    "        data_dict = {\n",
    "            'train_norm':Dataset_Custom,\n",
    "        }\n",
    "        Data = data_dict[args.data]\n",
    "        timeenc = 0 if args.embed!='timeF' else 1\n",
    "\n",
    "        if flag == 'test':\n",
    "            shuffle_flag = False; drop_last = True; batch_size = args.batch_size; freq=args.freq\n",
    "        elif flag=='pred':\n",
    "            shuffle_flag = False; drop_last = False; batch_size = 1; freq=args.detail_freq\n",
    "            Data = Dataset_Pred\n",
    "        else:\n",
    "            shuffle_flag = True; drop_last = True; batch_size = args.batch_size; freq=args.freq\n",
    "        data_set = Data(\n",
    "            root_path=args.root_path,\n",
    "            data_path=args.data_path,\n",
    "            flag=flag,\n",
    "            size=[args.seq_len, args.label_len, args.pred_len],\n",
    "            features=args.features,\n",
    "            target=args.target,\n",
    "            inverse=args.inverse,\n",
    "            timeenc=timeenc,\n",
    "            freq=freq,\n",
    "            cols=args.cols\n",
    "        )\n",
    "        data_loader = DataLoader(\n",
    "            data_set,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle_flag,\n",
    "            num_workers=args.num_workers,\n",
    "            drop_last=drop_last)\n",
    "\n",
    "        return data_set, data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_criterion():\n",
    "        criterion =  nn.MSELoss()\n",
    "        return criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_optimizer():\n",
    "        model_optim = optim.Adam(model.parameters(), lr=args.learning_rate)\n",
    "        return model_optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Informer(nn.Module):\n",
    "    def __init__(self, enc_in, dec_in, c_out, seq_len, label_len, out_len, \n",
    "                factor=5, d_model=512, n_heads=8, e_layers=3, d_layers=2, d_ff=512, \n",
    "                dropout=0.0, attn='prob', embed='fixed', freq='h', activation='gelu', \n",
    "                output_attention = False, distil=True, mix=True,\n",
    "                device=torch.device('cuda:0')):\n",
    "        super(Informer, self).__init__()\n",
    "        self.pred_len = out_len\n",
    "        self.attn = attn\n",
    "        self.output_attention = output_attention\n",
    "\n",
    "        # Encoding\n",
    "        self.enc_embedding = DataEmbedding(enc_in, d_model, embed, freq, dropout)\n",
    "        self.dec_embedding = DataEmbedding(dec_in, d_model, embed, freq, dropout)\n",
    "        # Attention\n",
    "        Attn = ProbAttention if attn=='prob' else FullAttention\n",
    "        # Encoder\n",
    "        self.encoder = Encoder(\n",
    "            [\n",
    "                EncoderLayer(\n",
    "                    AttentionLayer(Attn(False, factor, attention_dropout=dropout, output_attention=output_attention), \n",
    "                                d_model, n_heads, mix=False),\n",
    "                    d_model,\n",
    "                    d_ff,\n",
    "                    dropout=dropout,\n",
    "                    activation=activation\n",
    "                ) for l in range(e_layers)\n",
    "            ],\n",
    "            [\n",
    "                ConvLayer(\n",
    "                    d_model\n",
    "                ) for l in range(e_layers-1)\n",
    "            ] if distil else None,\n",
    "            norm_layer=torch.nn.LayerNorm(d_model)\n",
    "        )\n",
    "        # Decoder\n",
    "        self.decoder = Decoder(\n",
    "            [\n",
    "                DecoderLayer(\n",
    "                    AttentionLayer(Attn(True, factor, attention_dropout=dropout, output_attention=False), \n",
    "                                d_model, n_heads, mix=mix),\n",
    "                    AttentionLayer(FullAttention(False, factor, attention_dropout=dropout, output_attention=False), \n",
    "                                d_model, n_heads, mix=False),\n",
    "                    d_model,\n",
    "                    d_ff,\n",
    "                    dropout=dropout,\n",
    "                    activation=activation,\n",
    "                )\n",
    "                for l in range(d_layers)\n",
    "            ],\n",
    "            norm_layer=torch.nn.LayerNorm(d_model)\n",
    "        )\n",
    "        # self.end_conv1 = nn.Conv1d(in_channels=label_len+out_len, out_channels=out_len, kernel_size=1, bias=True)\n",
    "        # self.end_conv2 = nn.Conv1d(in_channels=d_model, out_channels=c_out, kernel_size=1, bias=True)\n",
    "        self.projection = nn.Linear(d_model, c_out, bias=True)\n",
    "        \n",
    "    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec, \n",
    "                enc_self_mask=None, dec_self_mask=None, dec_enc_mask=None):\n",
    "        enc_out = self.enc_embedding(x_enc, x_mark_enc)\n",
    "        enc_out, attns = self.encoder(enc_out, attn_mask=enc_self_mask)\n",
    "\n",
    "        dec_out = self.dec_embedding(x_dec, x_mark_dec)\n",
    "        dec_out = self.decoder(dec_out, enc_out, x_mask=dec_self_mask, cross_mask=dec_enc_mask)\n",
    "        dec_out = self.projection(dec_out)\n",
    "        \n",
    "        # dec_out = self.end_conv1(dec_out)\n",
    "        # dec_out = self.end_conv2(dec_out.transpose(2,1)).transpose(1,2)\n",
    "        if self.output_attention:\n",
    "            return dec_out[:,-self.pred_len:,:], attns\n",
    "        else:\n",
    "            return dec_out[:,-self.pred_len:,:] # [B, L, D]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'val'"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data=Dataset_Custom\n",
    "flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag=\"train\"\n",
    "train_data = Data(\n",
    "            root_path=args.root_path,\n",
    "            data_path=args.data_path,\n",
    "            flag=flag,\n",
    "            size=[args.seq_len, args.label_len, args.pred_len],\n",
    "            features=args.features,\n",
    "            target=args.target,\n",
    "            inverse=args.inverse,\n",
    "            timeenc=timeenc,\n",
    "            freq=args.freq,\n",
    "            cols=args.cols\n",
    "        )\n",
    "train_loader = DataLoader(\n",
    "            data_set,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle_flag,\n",
    "            num_workers=args.num_workers,\n",
    "            drop_last=drop_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "flag=\"val\"\n",
    "vali_data = Data(\n",
    "            root_path=args.root_path,\n",
    "            data_path=args.data_path,\n",
    "            flag=flag,\n",
    "            size=[args.seq_len, args.label_len, args.pred_len],\n",
    "            features=args.features,\n",
    "            target=args.target,\n",
    "            inverse=args.inverse,\n",
    "            timeenc=timeenc,\n",
    "            freq=args.freq,\n",
    "            cols=args.cols\n",
    "        )\n",
    "vali_loader = DataLoader(\n",
    "            data_set,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle_flag,\n",
    "            num_workers=args.num_workers,\n",
    "            drop_last=drop_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(vali_loader):\n",
    "    if i == 1:\n",
    "        train_x_dataframe= pd.DataFrame(batch_x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.274355</td>\n",
       "      <td>-2.107196</td>\n",
       "      <td>-0.684168</td>\n",
       "      <td>-0.654466</td>\n",
       "      <td>-1.638591</td>\n",
       "      <td>-0.573115</td>\n",
       "      <td>-1.269732</td>\n",
       "      <td>-0.664284</td>\n",
       "      <td>-1.800702</td>\n",
       "      <td>0.185467</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.00008</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>-0.001814</td>\n",
       "      <td>-0.00695</td>\n",
       "      <td>-0.637094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.274355</td>\n",
       "      <td>-2.107196</td>\n",
       "      <td>-0.684168</td>\n",
       "      <td>-0.522546</td>\n",
       "      <td>-1.638591</td>\n",
       "      <td>-0.526140</td>\n",
       "      <td>-0.600868</td>\n",
       "      <td>-0.664284</td>\n",
       "      <td>-1.917336</td>\n",
       "      <td>0.185467</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.00008</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>-0.001814</td>\n",
       "      <td>-0.00695</td>\n",
       "      <td>-0.478365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.274355</td>\n",
       "      <td>-1.059827</td>\n",
       "      <td>-0.677255</td>\n",
       "      <td>-0.522546</td>\n",
       "      <td>-0.635361</td>\n",
       "      <td>-0.526140</td>\n",
       "      <td>-0.600868</td>\n",
       "      <td>-0.468136</td>\n",
       "      <td>-1.917336</td>\n",
       "      <td>0.185467</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.00008</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>-0.001814</td>\n",
       "      <td>-0.00695</td>\n",
       "      <td>-0.478365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.274355</td>\n",
       "      <td>-1.059827</td>\n",
       "      <td>-0.677255</td>\n",
       "      <td>-0.605129</td>\n",
       "      <td>-0.635361</td>\n",
       "      <td>-0.552563</td>\n",
       "      <td>-1.269732</td>\n",
       "      <td>-0.468136</td>\n",
       "      <td>-1.323564</td>\n",
       "      <td>0.185467</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.00008</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>-0.001814</td>\n",
       "      <td>-0.00695</td>\n",
       "      <td>-0.617253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.274355</td>\n",
       "      <td>-0.270859</td>\n",
       "      <td>-0.497510</td>\n",
       "      <td>-0.605129</td>\n",
       "      <td>-0.133746</td>\n",
       "      <td>-0.552563</td>\n",
       "      <td>-1.269732</td>\n",
       "      <td>-0.666771</td>\n",
       "      <td>-1.323564</td>\n",
       "      <td>0.185467</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.00008</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>-0.001814</td>\n",
       "      <td>-0.00695</td>\n",
       "      <td>-0.617253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>-0.204419</td>\n",
       "      <td>-0.427187</td>\n",
       "      <td>-0.677255</td>\n",
       "      <td>-0.459520</td>\n",
       "      <td>-0.886169</td>\n",
       "      <td>-0.482618</td>\n",
       "      <td>-1.269732</td>\n",
       "      <td>-0.637948</td>\n",
       "      <td>0.419026</td>\n",
       "      <td>0.185467</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.00008</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>-0.001814</td>\n",
       "      <td>-0.00695</td>\n",
       "      <td>-0.147679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>-0.194059</td>\n",
       "      <td>-0.735770</td>\n",
       "      <td>-0.497510</td>\n",
       "      <td>-0.459520</td>\n",
       "      <td>-0.635361</td>\n",
       "      <td>-0.482618</td>\n",
       "      <td>-1.269732</td>\n",
       "      <td>-0.653157</td>\n",
       "      <td>0.419026</td>\n",
       "      <td>0.185467</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.00008</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>-0.001814</td>\n",
       "      <td>-0.00695</td>\n",
       "      <td>-0.147679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>-0.194059</td>\n",
       "      <td>-0.735770</td>\n",
       "      <td>-0.497510</td>\n",
       "      <td>-0.566110</td>\n",
       "      <td>-0.635361</td>\n",
       "      <td>-0.546272</td>\n",
       "      <td>-1.269732</td>\n",
       "      <td>-0.653157</td>\n",
       "      <td>-0.906069</td>\n",
       "      <td>0.185467</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.00008</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>-0.001814</td>\n",
       "      <td>-0.00695</td>\n",
       "      <td>-0.564343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>-0.202088</td>\n",
       "      <td>-0.880360</td>\n",
       "      <td>-0.677255</td>\n",
       "      <td>-0.566110</td>\n",
       "      <td>-0.133746</td>\n",
       "      <td>-0.546272</td>\n",
       "      <td>-1.269732</td>\n",
       "      <td>-0.562680</td>\n",
       "      <td>-0.906069</td>\n",
       "      <td>0.185467</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.00008</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>-0.001814</td>\n",
       "      <td>-0.00695</td>\n",
       "      <td>-0.564343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-0.202088</td>\n",
       "      <td>-0.880360</td>\n",
       "      <td>-0.677255</td>\n",
       "      <td>-0.580491</td>\n",
       "      <td>-0.133746</td>\n",
       "      <td>-0.495053</td>\n",
       "      <td>-0.868413</td>\n",
       "      <td>-0.562680</td>\n",
       "      <td>-1.033133</td>\n",
       "      <td>0.185467</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000052</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.00008</td>\n",
       "      <td>-0.000051</td>\n",
       "      <td>2.232712</td>\n",
       "      <td>-0.00695</td>\n",
       "      <td>-0.473956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6   \\\n",
       "0  -0.274355 -2.107196 -0.684168 -0.654466 -1.638591 -0.573115 -1.269732   \n",
       "1  -0.274355 -2.107196 -0.684168 -0.522546 -1.638591 -0.526140 -0.600868   \n",
       "2  -0.274355 -1.059827 -0.677255 -0.522546 -0.635361 -0.526140 -0.600868   \n",
       "3  -0.274355 -1.059827 -0.677255 -0.605129 -0.635361 -0.552563 -1.269732   \n",
       "4  -0.274355 -0.270859 -0.497510 -0.605129 -0.133746 -0.552563 -1.269732   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "91 -0.204419 -0.427187 -0.677255 -0.459520 -0.886169 -0.482618 -1.269732   \n",
       "92 -0.194059 -0.735770 -0.497510 -0.459520 -0.635361 -0.482618 -1.269732   \n",
       "93 -0.194059 -0.735770 -0.497510 -0.566110 -0.635361 -0.546272 -1.269732   \n",
       "94 -0.202088 -0.880360 -0.677255 -0.566110 -0.133746 -0.546272 -1.269732   \n",
       "95 -0.202088 -0.880360 -0.677255 -0.580491 -0.133746 -0.495053 -0.868413   \n",
       "\n",
       "          7         8         9   ...        46   47        48        49  \\\n",
       "0  -0.664284 -1.800702  0.185467  ... -0.000052 -1.0 -0.000019 -0.000006   \n",
       "1  -0.664284 -1.917336  0.185467  ... -0.000052 -1.0 -0.000019 -0.000006   \n",
       "2  -0.468136 -1.917336  0.185467  ... -0.000052 -1.0 -0.000019 -0.000006   \n",
       "3  -0.468136 -1.323564  0.185467  ... -0.000052 -1.0 -0.000019 -0.000006   \n",
       "4  -0.666771 -1.323564  0.185467  ... -0.000052 -1.0 -0.000019 -0.000006   \n",
       "..       ...       ...       ...  ...       ...  ...       ...       ...   \n",
       "91 -0.637948  0.419026  0.185467  ... -0.000052 -1.0 -0.000019 -0.000006   \n",
       "92 -0.653157  0.419026  0.185467  ... -0.000052 -1.0 -0.000019 -0.000006   \n",
       "93 -0.653157 -0.906069  0.185467  ... -0.000052 -1.0 -0.000019 -0.000006   \n",
       "94 -0.562680 -0.906069  0.185467  ... -0.000052 -1.0 -0.000019 -0.000006   \n",
       "95 -0.562680 -1.033133  0.185467  ... -0.000052 -1.0 -0.000019 -0.000006   \n",
       "\n",
       "          50       51        52        53       54        55  \n",
       "0  -0.000006 -0.00008 -0.000051 -0.001814 -0.00695 -0.637094  \n",
       "1  -0.000006 -0.00008 -0.000051 -0.001814 -0.00695 -0.478365  \n",
       "2  -0.000006 -0.00008 -0.000051 -0.001814 -0.00695 -0.478365  \n",
       "3  -0.000006 -0.00008 -0.000051 -0.001814 -0.00695 -0.617253  \n",
       "4  -0.000006 -0.00008 -0.000051 -0.001814 -0.00695 -0.617253  \n",
       "..       ...      ...       ...       ...      ...       ...  \n",
       "91 -0.000006 -0.00008 -0.000051 -0.001814 -0.00695 -0.147679  \n",
       "92 -0.000006 -0.00008 -0.000051 -0.001814 -0.00695 -0.147679  \n",
       "93 -0.000006 -0.00008 -0.000051 -0.001814 -0.00695 -0.564343  \n",
       "94 -0.000006 -0.00008 -0.000051 -0.001814 -0.00695 -0.564343  \n",
       "95 -0.000006 -0.00008 -0.000051  2.232712 -0.00695 -0.473956  \n",
       "\n",
       "[96 rows x 56 columns]"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# count the total number of NaN values in the dataframe\n",
    "total_nan_count = train_x_dataframe.isna().sum().sum()\n",
    "print(\"Nulos\",total_nan_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# count the total number of zeros in the dataframe\n",
    "total_zero_count = (train_x_dataframe == 0).sum().sum()\n",
    "print(total_zero_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-2.1206e-01,  2.0439e+00,  1.5925e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03,  3.7291e-01],\n",
      "         [-2.1206e-01,  2.0439e+00,  1.5925e-01,  ..., -1.8138e-03,\n",
      "          -4.3811e+00,  1.1582e+00],\n",
      "         [ 2.0611e-02,  3.0286e+00,  2.0604e+00,  ..., -1.8138e-03,\n",
      "          -4.3811e+00,  1.1582e+00],\n",
      "         ...,\n",
      "         [-2.7435e-01, -5.1617e-01, -4.9751e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -4.6514e-01],\n",
      "         [-1.8009e-01, -1.3986e+00, -1.3583e-02,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -4.6514e-01],\n",
      "         [-1.8009e-01, -1.3986e+00, -1.3583e-02,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -5.7977e-01]],\n",
      "\n",
      "        [[-2.7435e-01, -7.4947e-02, -6.7725e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -5.1805e-01],\n",
      "         [-2.0660e-01, -1.1915e-02, -6.7725e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -5.1805e-01],\n",
      "         [-2.0660e-01, -1.1915e-02, -6.7725e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -4.8718e-01],\n",
      "         ...,\n",
      "         [-1.9406e-01, -5.5598e-01, -4.2838e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -6.0072e-01],\n",
      "         [-1.9406e-01, -5.5598e-01, -4.2838e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -5.9906e-01],\n",
      "         [-2.2394e-01,  2.4021e-01, -4.2838e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -5.9906e-01]],\n",
      "\n",
      "        [[-2.0660e-01, -1.1915e-02, -6.7725e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -4.8718e-01],\n",
      "         [-2.7435e-01, -1.7264e+00, -4.9751e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -4.8718e-01],\n",
      "         [-2.7435e-01, -1.7264e+00, -4.9751e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -3.7255e-01],\n",
      "         ...,\n",
      "         [-2.2394e-01,  2.4021e-01, -4.2838e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -5.9906e-01],\n",
      "         [-2.2394e-01,  2.4021e-01, -4.2838e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03,  3.3733e-01],\n",
      "         [-2.3185e-01,  4.4597e-02, -4.9751e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03,  3.3733e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.7435e-01,  2.4021e-01, -6.7725e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -6.0072e-01],\n",
      "         [-1.9406e-01, -5.5598e-01, -4.2838e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -6.0072e-01],\n",
      "         [-1.9406e-01, -5.5598e-01, -4.2838e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -5.9906e-01],\n",
      "         ...,\n",
      "         [-2.2587e-02,  2.8876e+00,  2.9822e+00,  ..., -1.8138e-03,\n",
      "           4.3681e+00,  1.4866e+00],\n",
      "         [-2.2587e-02,  2.8876e+00,  2.9822e+00,  ..., -1.8138e-03,\n",
      "          -6.9502e-03,  1.0322e+00],\n",
      "         [-8.3462e-02,  1.3667e+00,  4.0121e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03,  1.0322e+00]],\n",
      "\n",
      "        [[-2.1241e-01, -1.1997e-01, -4.2838e-01,  ...,  2.2327e+00,\n",
      "          -6.9502e-03, -7.8235e-02],\n",
      "         [-2.1241e-01, -1.1997e-01, -4.2838e-01,  ..., -2.2359e+00,\n",
      "          -6.9502e-03, -1.4024e-01],\n",
      "         [-2.7435e-01,  1.5975e-01,  1.2468e-01,  ..., -2.2359e+00,\n",
      "          -6.9502e-03, -1.4024e-01],\n",
      "         ...,\n",
      "         [-1.1572e-01, -5.7020e-01, -6.8417e-01,  ...,  2.2327e+00,\n",
      "          -6.9502e-03,  3.4174e-01],\n",
      "         [-2.0866e-01, -7.0527e-01, -4.2838e-01,  ...,  2.2327e+00,\n",
      "          -6.9502e-03,  3.4174e-01],\n",
      "         [-2.0866e-01, -7.0527e-01, -4.2838e-01,  ..., -2.2359e+00,\n",
      "          -6.9502e-03, -4.5191e-01]],\n",
      "\n",
      "        [[-1.9552e-01, -4.7336e-01, -4.2838e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -3.5822e-01],\n",
      "         [-1.9552e-01, -4.7336e-01, -4.2838e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -4.5456e-01],\n",
      "         [-2.7435e-01, -8.5815e-02,  5.5550e-02,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -4.5456e-01],\n",
      "         ...,\n",
      "         [-2.7435e-01,  3.4243e-01, -4.9751e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -3.0641e-01],\n",
      "         [-2.1877e-01, -4.0548e-01, -6.8417e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -3.0641e-01],\n",
      "         [-2.1877e-01, -4.0548e-01, -6.8417e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -4.1223e-01]]], dtype=torch.float64)\n",
      "tensor([[[-2.0660e-01, -7.6830e-01, -6.8417e-01,  ..., -2.2359e+00,\n",
      "          -6.9502e-03, -4.6734e-01],\n",
      "         [-2.0660e-01, -7.6830e-01, -6.8417e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -4.5569e-01],\n",
      "         [-2.7435e-01, -6.1932e-01,  2.6295e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -4.5569e-01],\n",
      "         ...,\n",
      "         [-2.2082e-01, -9.2015e-01, -1.3583e-02,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -1.1975e-01],\n",
      "         [-2.1328e-01, -1.1277e-01, -4.2838e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -1.1975e-01],\n",
      "         [-2.1328e-01, -1.1277e-01, -4.2838e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -4.0341e-01]],\n",
      "\n",
      "        [[-1.9406e-01, -5.5598e-01, -4.2838e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -6.0072e-01],\n",
      "         [-1.9406e-01, -5.5598e-01, -4.2838e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -5.9906e-01],\n",
      "         [-2.2394e-01,  2.4021e-01, -4.2838e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -5.9906e-01],\n",
      "         ...,\n",
      "         [-2.2587e-02,  2.8876e+00,  2.9822e+00,  ..., -1.8138e-03,\n",
      "          -6.9502e-03,  1.0322e+00],\n",
      "         [-8.3462e-02,  1.3667e+00,  4.0121e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03,  1.0322e+00],\n",
      "         [-8.3462e-02,  1.3667e+00,  4.0121e-01,  ...,  2.2327e+00,\n",
      "          -6.9502e-03,  1.4280e+00]],\n",
      "\n",
      "        [[-2.0209e-01,  4.1165e-02, -4.9751e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -4.2876e-01],\n",
      "         [-2.0209e-01,  4.1165e-02, -4.9751e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -3.9753e-01],\n",
      "         [-2.7435e-01, -7.0527e-01, -1.5185e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -3.9753e-01],\n",
      "         ...,\n",
      "         [-8.2497e-02,  2.2025e-02,  1.3691e+00,  ..., -2.2359e+00,\n",
      "          -6.9502e-03,  1.0707e+00],\n",
      "         [-1.6124e-01,  5.4277e-01,  2.7517e+00,  ..., -2.2359e+00,\n",
      "          -6.9502e-03,  1.0707e+00],\n",
      "         [-1.6124e-01,  5.4277e-01,  2.7517e+00,  ..., -1.8138e-03,\n",
      "          -6.9502e-03,  1.1158e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.5129e-01,  1.0476e+00,  1.7147e+00,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -3.6226e-01],\n",
      "         [-2.4656e-01,  3.3719e-01, -4.2838e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -3.6226e-01],\n",
      "         [-2.4656e-01,  3.3719e-01, -4.2838e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -3.9900e-01],\n",
      "         ...,\n",
      "         [-2.1730e-01, -4.5646e-01, -6.7725e-01,  ...,  2.2327e+00,\n",
      "          -6.9502e-03,  3.0891e-02],\n",
      "         [-2.1730e-01, -4.5646e-01, -6.7725e-01,  ..., -2.2359e+00,\n",
      "          -6.9502e-03, -4.7836e-01],\n",
      "         [-2.0866e-01, -4.5646e-01, -4.2838e-01,  ..., -2.2359e+00,\n",
      "          -6.9502e-03, -4.7836e-01]],\n",
      "\n",
      "        [[-2.3306e-01, -4.9302e-01,  4.0121e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -3.5779e-01],\n",
      "         [-2.3306e-01, -4.9302e-01,  4.0121e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -2.1293e-01],\n",
      "         [-2.1576e-01, -1.0061e+00,  2.6295e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -2.1293e-01],\n",
      "         ...,\n",
      "         [-1.5047e-01,  1.8286e+00,  3.3208e-01,  ...,  2.2327e+00,\n",
      "          -4.3811e+00,  7.5717e-02],\n",
      "         [-1.8676e-01,  2.4021e-01,  2.6295e-01,  ...,  2.2327e+00,\n",
      "          -4.3811e+00,  7.5717e-02],\n",
      "         [-1.8676e-01,  2.4021e-01,  2.6295e-01,  ..., -2.2359e+00,\n",
      "           4.3681e+00, -1.9814e-02]],\n",
      "\n",
      "        [[-2.7435e-01,  1.0514e-01, -4.2838e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -6.8315e-02],\n",
      "         [ 8.6978e-02, -1.3798e-01, -6.7725e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -6.8315e-02],\n",
      "         [ 8.6978e-02, -1.3798e-01, -6.7725e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -3.6688e-01],\n",
      "         ...,\n",
      "         [-2.4656e-01,  3.3719e-01, -4.2838e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -3.6226e-01],\n",
      "         [-2.4656e-01,  3.3719e-01, -4.2838e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -3.9900e-01],\n",
      "         [-2.0086e-01, -1.2726e+00,  2.4061e+00,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -3.9900e-01]]], dtype=torch.float64)\n",
      "tensor([[[-2.7435e-01, -7.4947e-02, -6.7725e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -5.7977e-01],\n",
      "         [-2.7435e-01, -7.4947e-02, -6.7725e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -5.1805e-01],\n",
      "         [-2.0660e-01, -1.1915e-02, -6.7725e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -5.1805e-01],\n",
      "         ...,\n",
      "         [-2.7435e-01,  2.4021e-01, -6.7725e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -6.0072e-01],\n",
      "         [-1.9406e-01, -5.5598e-01, -4.2838e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -6.0072e-01],\n",
      "         [-1.9406e-01, -5.5598e-01, -4.2838e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -5.9906e-01]],\n",
      "\n",
      "        [[-2.3185e-01,  4.4597e-02, -4.9751e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03,  3.3733e-01],\n",
      "         [-2.3185e-01,  4.4597e-02, -4.9751e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -3.8511e-01],\n",
      "         [-1.7581e-01,  1.9294e-01,  1.2468e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -3.8511e-01],\n",
      "         ...,\n",
      "         [ 6.9534e-02,  1.5672e+00,  2.6295e-01,  ..., -2.2359e+00,\n",
      "          -6.9502e-03,  3.4240e-01],\n",
      "         [ 2.9441e-02,  3.2138e+00,  2.6295e-01,  ..., -2.2359e+00,\n",
      "          -6.9502e-03,  3.4240e-01],\n",
      "         [ 2.9441e-02,  3.2138e+00,  2.6295e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03,  2.5708e-01]],\n",
      "\n",
      "        [[-2.1970e-01,  1.1281e+00,  1.2468e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03,  1.0957e+00],\n",
      "         [ 5.3184e-02,  1.2340e+00,  2.0604e+00,  ..., -1.8138e-03,\n",
      "          -6.9502e-03,  1.0957e+00],\n",
      "         [ 5.3184e-02,  1.2340e+00,  2.0604e+00,  ..., -1.8138e-03,\n",
      "          -6.9502e-03,  3.7291e-01],\n",
      "         ...,\n",
      "         [-2.7435e-01, -9.4839e-01, -4.2838e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -6.5859e-01],\n",
      "         [-2.7435e-01, -9.4839e-01, -4.2838e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -5.9873e-01],\n",
      "         [-2.7435e-01, -5.1617e-01, -4.9751e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -5.9873e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-2.4583e-01, -1.9201e-01,  4.0121e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -7.8897e-02],\n",
      "         [-2.4583e-01, -1.9201e-01,  4.0121e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -3.9073e-01],\n",
      "         [-2.7435e-01, -2.4112e-01, -4.9751e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -3.9073e-01],\n",
      "         ...,\n",
      "         [-2.7435e-01, -8.1032e-01, -4.2838e-01,  ..., -1.8138e-03,\n",
      "          -4.3811e+00,  2.9740e+00],\n",
      "         [-5.0079e-02,  1.1479e+00, -6.7725e-01,  ..., -1.8138e-03,\n",
      "          -4.3811e+00,  2.9740e+00],\n",
      "         [-5.0079e-02,  1.1479e+00, -6.7725e-01,  ..., -1.8138e-03,\n",
      "           4.3681e+00, -6.3415e-01]],\n",
      "\n",
      "        [[ 3.5506e-01,  1.9057e+00,  3.3208e-01,  ..., -1.8138e-03,\n",
      "           4.3681e+00,  6.2398e-03],\n",
      "         [-2.5446e-01,  1.1227e+00,  3.0904e-01,  ..., -1.8138e-03,\n",
      "           4.3681e+00,  6.2398e-03],\n",
      "         [-2.5446e-01,  1.1227e+00,  3.0904e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03,  3.8142e-01],\n",
      "         ...,\n",
      "         [-2.7435e-01, -8.5815e-02,  5.5550e-02,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -4.5456e-01],\n",
      "         [-2.7435e-01, -8.5815e-02,  5.5550e-02,  ...,  2.2327e+00,\n",
      "          -6.9502e-03, -6.2188e-01],\n",
      "         [-2.1576e-01, -9.4839e-01, -4.9751e-01,  ...,  2.2327e+00,\n",
      "          -6.9502e-03, -6.2188e-01]],\n",
      "\n",
      "        [[-1.7581e-01,  1.9294e-01,  1.2468e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -3.8511e-01],\n",
      "         [-1.7581e-01,  1.9294e-01,  1.2468e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -1.9067e-01],\n",
      "         [-2.2871e-01,  1.9724e-01,  1.3691e+00,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -1.9067e-01],\n",
      "         ...,\n",
      "         [ 2.9441e-02,  3.2138e+00,  2.6295e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03,  2.5708e-01],\n",
      "         [-7.4468e-02,  1.1619e+00,  1.3691e+00,  ..., -1.8138e-03,\n",
      "          -6.9502e-03,  2.5708e-01],\n",
      "         [-7.4468e-02,  1.1619e+00,  1.3691e+00,  ..., -1.8138e-03,\n",
      "          -6.9502e-03,  3.9310e+00]]], dtype=torch.float64)\n",
      "tensor([[[-2.7435e-01, -1.7645e-02, -1.3583e-02,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -4.9821e-01],\n",
      "         [-2.7435e-01, -1.7645e-02, -1.3583e-02,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -4.4133e-01],\n",
      "         [-7.1105e-02,  3.8430e-03, -4.9751e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -4.4133e-01],\n",
      "         ...,\n",
      "         [-2.1241e-01,  6.0122e-02, -4.2838e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -6.2093e-01],\n",
      "         [-2.0442e-01, -4.2719e-01, -6.7725e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -6.2093e-01],\n",
      "         [-2.0442e-01, -4.2719e-01, -6.7725e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -1.4768e-01]],\n",
      "\n",
      "        [[-2.7435e-01, -2.7086e-01, -4.9751e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -1.6091e-01],\n",
      "         [-2.7435e-01, -5.3557e-01, -1.3583e-02,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -1.6091e-01],\n",
      "         [-2.7435e-01, -5.3557e-01, -1.3583e-02,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -4.1223e-01],\n",
      "         ...,\n",
      "         [-2.0660e-01, -7.6830e-01, -6.8417e-01,  ..., -2.2359e+00,\n",
      "          -6.9502e-03, -4.6734e-01],\n",
      "         [-2.0660e-01, -7.6830e-01, -6.8417e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -4.5569e-01],\n",
      "         [-2.7435e-01, -6.1932e-01,  2.6295e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -4.5569e-01]],\n",
      "\n",
      "        [[-2.7435e-01, -3.5071e-01,  1.3691e+00,  ...,  2.2327e+00,\n",
      "          -6.9502e-03, -4.1860e-02],\n",
      "         [-2.7435e-01, -3.5071e-01,  1.3691e+00,  ..., -2.2359e+00,\n",
      "          -6.9502e-03, -4.1860e-02],\n",
      "         [-2.0866e-01, -2.2811e+00, -6.7725e-01,  ..., -2.2359e+00,\n",
      "          -6.9502e-03, -4.1860e-02],\n",
      "         ...,\n",
      "         [-2.2722e-01, -1.1105e+00,  1.3691e+00,  ...,  2.2327e+00,\n",
      "          -6.9502e-03, -5.4120e-01],\n",
      "         [-2.3632e-01, -6.3254e-01, -4.9751e-01,  ...,  2.2327e+00,\n",
      "          -6.9502e-03, -5.4120e-01],\n",
      "         [-2.3632e-01, -6.3254e-01, -4.9751e-01,  ..., -2.2359e+00,\n",
      "          -6.9502e-03, -1.7149e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.3885e-01, -6.2423e-01, -4.9751e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -4.8498e-01],\n",
      "         [-1.3885e-01, -6.2423e-01, -4.9751e-01,  ...,  2.2327e+00,\n",
      "          -6.9502e-03, -6.1990e-01],\n",
      "         [-2.7435e-01,  2.4021e-01, -5.8047e-01,  ...,  2.2327e+00,\n",
      "          -6.9502e-03, -6.1990e-01],\n",
      "         ...,\n",
      "         [-2.3306e-01, -4.9302e-01,  4.0121e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -2.1293e-01],\n",
      "         [-2.1576e-01, -1.0061e+00,  2.6295e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -2.1293e-01],\n",
      "         [-2.1576e-01, -1.0061e+00,  2.6295e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -1.2784e-01]],\n",
      "\n",
      "        [[-2.1206e-01,  2.0439e+00,  1.5925e-01,  ..., -1.8138e-03,\n",
      "          -4.3811e+00,  1.1582e+00],\n",
      "         [ 2.0611e-02,  3.0286e+00,  2.0604e+00,  ..., -1.8138e-03,\n",
      "          -4.3811e+00,  1.1582e+00],\n",
      "         [ 2.0611e-02,  3.0286e+00,  2.0604e+00,  ..., -1.8138e-03,\n",
      "          -6.9502e-03,  7.8517e-01],\n",
      "         ...,\n",
      "         [-1.8009e-01, -1.3986e+00, -1.3583e-02,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -4.6514e-01],\n",
      "         [-1.8009e-01, -1.3986e+00, -1.3583e-02,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -5.7977e-01],\n",
      "         [-2.7435e-01, -8.2346e-01, -6.8417e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -5.7977e-01]],\n",
      "\n",
      "        [[-2.7435e-01, -1.1997e-01, -4.2838e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -3.7784e-01],\n",
      "         [-2.7435e-01, -1.1997e-01, -4.2838e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -2.0059e-01],\n",
      "         [-1.9960e-01,  3.7063e-01, -4.9751e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -2.0059e-01],\n",
      "         ...,\n",
      "         [-2.0866e-01, -2.2811e+00, -6.7725e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -4.8101e-01],\n",
      "         [-2.7435e-01, -3.7819e-03, -4.9751e-01,  ..., -1.8138e-03,\n",
      "          -6.9502e-03, -4.8101e-01],\n",
      "         [-2.7435e-01, -3.7819e-03, -4.9751e-01,  ...,  2.2327e+00,\n",
      "          -6.9502e-03,  9.6783e-01]]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(vali_loader):\n",
    "    print(batch_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(277, 56)"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(277, 56)"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_set.data_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 24, 1])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true = batch_y[:,-args.pred_len:,f_dim:]\n",
    "pred = batch_y[:,-args.pred_len:,:]\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1709 1805\n"
     ]
    }
   ],
   "source": [
    "border1 = len(df_raw)-args.seq_len\n",
    "border2 = len(df_raw)\n",
    "print(border1,border2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 57)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1=df_raw.values\n",
    "d2=d1[border1:border2]\n",
    "d2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Es 35 por cada batch\n",
    "train_steps = len(data_loader)\n",
    "train_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x14d605a90>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 24, 56])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ENTRADA DEL DECODER (Lo que va a predecir lo coloca en ceros)\n",
    "dec_inp = torch.zeros([batch_y.shape[0],args.pred_len, batch_y.shape[-1]]).float()\n",
    "dec_inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 72, 56])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec_input = torch.cat([batch_y[:,:args.label_len,:], dec_inp], dim=1).float()\n",
    "dec_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataLoader' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[380], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data_loader\u001b[39m.\u001b[39;49mshape\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataLoader' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "data_loader.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n",
      "torch.Size([32, 72, 56])\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(train_steps):\n",
    "    for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(data_loader):\n",
    "        print(batch_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5,)\n"
     ]
    }
   ],
   "source": [
    "# Filter the rows that have more than 0 zeros\n",
    "filtered_rows = df.index[df.eq(0).sum(axis=1) > 0]\n",
    "\n",
    "# Print the filtered rows\n",
    "print(filtered_rows.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>p50 deploy/adservice</th>\n",
       "      <th>p50 deploy/cartservice</th>\n",
       "      <th>p50 deploy/checkoutservice</th>\n",
       "      <th>p50 deploy/currencyservice</th>\n",
       "      <th>p50 deploy/emailservice</th>\n",
       "      <th>p50 deploy/frontend</th>\n",
       "      <th>p50 deploy/paymentservice</th>\n",
       "      <th>p50 deploy/productcatalogservice</th>\n",
       "      <th>p50 deploy/recommendationservice</th>\n",
       "      <th>...</th>\n",
       "      <th>deploy/cartservice</th>\n",
       "      <th>deploy/checkoutservice</th>\n",
       "      <th>deploy/currencyservice</th>\n",
       "      <th>deploy/emailservice</th>\n",
       "      <th>deploy/frontend</th>\n",
       "      <th>deploy/loadgenerator</th>\n",
       "      <th>deploy/productcatalogservice</th>\n",
       "      <th>deploy/recommendationservice</th>\n",
       "      <th>deploy/shippingservice</th>\n",
       "      <th>p95 deploy/frontend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-10-07 09:18:00</td>\n",
       "      <td>13.460422</td>\n",
       "      <td>-1.643790</td>\n",
       "      <td>-0.057770</td>\n",
       "      <td>-0.217764</td>\n",
       "      <td>-1.146121</td>\n",
       "      <td>-0.346990</td>\n",
       "      <td>-0.644470</td>\n",
       "      <td>-0.522305</td>\n",
       "      <td>0.705090</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000056</td>\n",
       "      <td>-0.000104</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000067</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.001252</td>\n",
       "      <td>4.805699</td>\n",
       "      <td>-0.535875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-10-07 09:18:05</td>\n",
       "      <td>10.031784</td>\n",
       "      <td>0.229134</td>\n",
       "      <td>-0.434722</td>\n",
       "      <td>-0.217764</td>\n",
       "      <td>-0.898530</td>\n",
       "      <td>-0.346990</td>\n",
       "      <td>-0.644470</td>\n",
       "      <td>-0.429260</td>\n",
       "      <td>0.705090</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000056</td>\n",
       "      <td>-0.000104</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000067</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.001252</td>\n",
       "      <td>4.805699</td>\n",
       "      <td>-0.535875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-10-07 09:18:10</td>\n",
       "      <td>10.031784</td>\n",
       "      <td>0.229134</td>\n",
       "      <td>-0.434722</td>\n",
       "      <td>-0.228521</td>\n",
       "      <td>-0.898530</td>\n",
       "      <td>-0.393260</td>\n",
       "      <td>0.922269</td>\n",
       "      <td>-0.429260</td>\n",
       "      <td>-0.498528</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000056</td>\n",
       "      <td>-0.000104</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000067</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.001252</td>\n",
       "      <td>-0.005351</td>\n",
       "      <td>-0.623315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-10-07 09:18:15</td>\n",
       "      <td>8.460325</td>\n",
       "      <td>-0.890356</td>\n",
       "      <td>-0.010651</td>\n",
       "      <td>-0.228521</td>\n",
       "      <td>-0.452866</td>\n",
       "      <td>-0.393260</td>\n",
       "      <td>0.922269</td>\n",
       "      <td>-0.592773</td>\n",
       "      <td>-0.498528</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000056</td>\n",
       "      <td>-0.000104</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000067</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.001252</td>\n",
       "      <td>-0.005351</td>\n",
       "      <td>-0.623315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-10-07 09:18:20</td>\n",
       "      <td>8.460325</td>\n",
       "      <td>-0.890356</td>\n",
       "      <td>-0.010651</td>\n",
       "      <td>-0.325898</td>\n",
       "      <td>-0.452866</td>\n",
       "      <td>-0.392411</td>\n",
       "      <td>0.400022</td>\n",
       "      <td>-0.592773</td>\n",
       "      <td>-0.798506</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000056</td>\n",
       "      <td>-0.000104</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000067</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.001252</td>\n",
       "      <td>-0.005351</td>\n",
       "      <td>-0.237772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1800</th>\n",
       "      <td>2021-10-07 11:48:00</td>\n",
       "      <td>-0.254131</td>\n",
       "      <td>0.002309</td>\n",
       "      <td>-0.010651</td>\n",
       "      <td>-0.722205</td>\n",
       "      <td>0.587018</td>\n",
       "      <td>-0.532381</td>\n",
       "      <td>0.086675</td>\n",
       "      <td>-0.670068</td>\n",
       "      <td>-0.714562</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000056</td>\n",
       "      <td>-0.000104</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000067</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-2.177623</td>\n",
       "      <td>-0.005351</td>\n",
       "      <td>-0.463400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1801</th>\n",
       "      <td>2021-10-07 11:48:05</td>\n",
       "      <td>-0.254131</td>\n",
       "      <td>-0.166355</td>\n",
       "      <td>-0.434722</td>\n",
       "      <td>-0.722205</td>\n",
       "      <td>0.215631</td>\n",
       "      <td>-0.532381</td>\n",
       "      <td>0.086675</td>\n",
       "      <td>-0.586403</td>\n",
       "      <td>-0.714562</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000056</td>\n",
       "      <td>-0.000104</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000067</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-2.177623</td>\n",
       "      <td>-0.005351</td>\n",
       "      <td>-0.463400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1802</th>\n",
       "      <td>2021-10-07 11:48:10</td>\n",
       "      <td>-0.254131</td>\n",
       "      <td>-0.166355</td>\n",
       "      <td>-0.434722</td>\n",
       "      <td>0.248105</td>\n",
       "      <td>0.215631</td>\n",
       "      <td>-0.503038</td>\n",
       "      <td>-0.748919</td>\n",
       "      <td>-0.586403</td>\n",
       "      <td>-0.665183</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000056</td>\n",
       "      <td>-0.000104</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000067</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.001252</td>\n",
       "      <td>-0.005351</td>\n",
       "      <td>0.627135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1803</th>\n",
       "      <td>2021-10-07 11:48:15</td>\n",
       "      <td>0.031589</td>\n",
       "      <td>0.688184</td>\n",
       "      <td>0.554777</td>\n",
       "      <td>0.248105</td>\n",
       "      <td>-0.650939</td>\n",
       "      <td>-0.503038</td>\n",
       "      <td>-0.748919</td>\n",
       "      <td>-0.471991</td>\n",
       "      <td>-0.665183</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000056</td>\n",
       "      <td>-0.000104</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000067</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.001252</td>\n",
       "      <td>-0.005351</td>\n",
       "      <td>0.627135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1804</th>\n",
       "      <td>2021-10-07 11:48:20</td>\n",
       "      <td>0.031589</td>\n",
       "      <td>0.688184</td>\n",
       "      <td>0.554777</td>\n",
       "      <td>0.727939</td>\n",
       "      <td>-0.650939</td>\n",
       "      <td>-0.291437</td>\n",
       "      <td>-0.470388</td>\n",
       "      <td>-0.471991</td>\n",
       "      <td>1.650441</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000056</td>\n",
       "      <td>-0.000104</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000067</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>2.175554</td>\n",
       "      <td>-0.005351</td>\n",
       "      <td>3.618416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1805 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     date  p50 deploy/adservice  p50 deploy/cartservice  \\\n",
       "0     2021-10-07 09:18:00             13.460422               -1.643790   \n",
       "1     2021-10-07 09:18:05             10.031784                0.229134   \n",
       "2     2021-10-07 09:18:10             10.031784                0.229134   \n",
       "3     2021-10-07 09:18:15              8.460325               -0.890356   \n",
       "4     2021-10-07 09:18:20              8.460325               -0.890356   \n",
       "...                   ...                   ...                     ...   \n",
       "1800  2021-10-07 11:48:00             -0.254131                0.002309   \n",
       "1801  2021-10-07 11:48:05             -0.254131               -0.166355   \n",
       "1802  2021-10-07 11:48:10             -0.254131               -0.166355   \n",
       "1803  2021-10-07 11:48:15              0.031589                0.688184   \n",
       "1804  2021-10-07 11:48:20              0.031589                0.688184   \n",
       "\n",
       "      p50 deploy/checkoutservice  p50 deploy/currencyservice  \\\n",
       "0                      -0.057770                   -0.217764   \n",
       "1                      -0.434722                   -0.217764   \n",
       "2                      -0.434722                   -0.228521   \n",
       "3                      -0.010651                   -0.228521   \n",
       "4                      -0.010651                   -0.325898   \n",
       "...                          ...                         ...   \n",
       "1800                   -0.010651                   -0.722205   \n",
       "1801                   -0.434722                   -0.722205   \n",
       "1802                   -0.434722                    0.248105   \n",
       "1803                    0.554777                    0.248105   \n",
       "1804                    0.554777                    0.727939   \n",
       "\n",
       "      p50 deploy/emailservice  p50 deploy/frontend  p50 deploy/paymentservice  \\\n",
       "0                   -1.146121            -0.346990                  -0.644470   \n",
       "1                   -0.898530            -0.346990                  -0.644470   \n",
       "2                   -0.898530            -0.393260                   0.922269   \n",
       "3                   -0.452866            -0.393260                   0.922269   \n",
       "4                   -0.452866            -0.392411                   0.400022   \n",
       "...                       ...                  ...                        ...   \n",
       "1800                 0.587018            -0.532381                   0.086675   \n",
       "1801                 0.215631            -0.532381                   0.086675   \n",
       "1802                 0.215631            -0.503038                  -0.748919   \n",
       "1803                -0.650939            -0.503038                  -0.748919   \n",
       "1804                -0.650939            -0.291437                  -0.470388   \n",
       "\n",
       "      p50 deploy/productcatalogservice  p50 deploy/recommendationservice  ...  \\\n",
       "0                            -0.522305                          0.705090  ...   \n",
       "1                            -0.429260                          0.705090  ...   \n",
       "2                            -0.429260                         -0.498528  ...   \n",
       "3                            -0.592773                         -0.498528  ...   \n",
       "4                            -0.592773                         -0.798506  ...   \n",
       "...                                ...                               ...  ...   \n",
       "1800                         -0.670068                         -0.714562  ...   \n",
       "1801                         -0.586403                         -0.714562  ...   \n",
       "1802                         -0.586403                         -0.665183  ...   \n",
       "1803                         -0.471991                         -0.665183  ...   \n",
       "1804                         -0.471991                          1.650441  ...   \n",
       "\n",
       "      deploy/cartservice  deploy/checkoutservice  deploy/currencyservice  \\\n",
       "0              -0.000056               -0.000104               -0.000017   \n",
       "1              -0.000056               -0.000104               -0.000017   \n",
       "2              -0.000056               -0.000104               -0.000017   \n",
       "3              -0.000056               -0.000104               -0.000017   \n",
       "4              -0.000056               -0.000104               -0.000017   \n",
       "...                  ...                     ...                     ...   \n",
       "1800           -0.000056               -0.000104               -0.000017   \n",
       "1801           -0.000056               -0.000104               -0.000017   \n",
       "1802           -0.000056               -0.000104               -0.000017   \n",
       "1803           -0.000056               -0.000104               -0.000017   \n",
       "1804           -0.000056               -0.000104               -0.000017   \n",
       "\n",
       "      deploy/emailservice  deploy/frontend  deploy/loadgenerator  \\\n",
       "0               -0.000005        -0.000005             -0.000067   \n",
       "1               -0.000005        -0.000005             -0.000067   \n",
       "2               -0.000005        -0.000005             -0.000067   \n",
       "3               -0.000005        -0.000005             -0.000067   \n",
       "4               -0.000005        -0.000005             -0.000067   \n",
       "...                   ...              ...                   ...   \n",
       "1800            -0.000005        -0.000005             -0.000067   \n",
       "1801            -0.000005        -0.000005             -0.000067   \n",
       "1802            -0.000005        -0.000005             -0.000067   \n",
       "1803            -0.000005        -0.000005             -0.000067   \n",
       "1804            -0.000005        -0.000005             -0.000067   \n",
       "\n",
       "      deploy/productcatalogservice  deploy/recommendationservice  \\\n",
       "0                        -0.000055                     -0.001252   \n",
       "1                        -0.000055                     -0.001252   \n",
       "2                        -0.000055                     -0.001252   \n",
       "3                        -0.000055                     -0.001252   \n",
       "4                        -0.000055                     -0.001252   \n",
       "...                            ...                           ...   \n",
       "1800                     -0.000055                     -2.177623   \n",
       "1801                     -0.000055                     -2.177623   \n",
       "1802                     -0.000055                     -0.001252   \n",
       "1803                     -0.000055                     -0.001252   \n",
       "1804                     -0.000055                      2.175554   \n",
       "\n",
       "      deploy/shippingservice  p95 deploy/frontend  \n",
       "0                   4.805699            -0.535875  \n",
       "1                   4.805699            -0.535875  \n",
       "2                  -0.005351            -0.623315  \n",
       "3                  -0.005351            -0.623315  \n",
       "4                  -0.005351            -0.237772  \n",
       "...                      ...                  ...  \n",
       "1800               -0.005351            -0.463400  \n",
       "1801               -0.005351            -0.463400  \n",
       "1802               -0.005351             0.627135  \n",
       "1803               -0.005351             0.627135  \n",
       "1804               -0.005351             3.618416  \n",
       "\n",
       "[1805 rows x 57 columns]"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(self, setting):\n",
    "        train_data, train_loader = self._get_data(flag = 'train')\n",
    "        vali_data, vali_loader = self._get_data(flag = 'val')\n",
    "        test_data, test_loader = self._get_data(flag = 'test')\n",
    "\n",
    "        path = os.path.join(self.args.checkpoints, setting)\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "\n",
    "        time_now = time.time()\n",
    "        \n",
    "        train_steps = len(train_loader)\n",
    "        early_stopping = EarlyStopping(patience=self.args.patience, verbose=True)\n",
    "        \n",
    "        model_optim = self._select_optimizer()\n",
    "        criterion =  self._select_criterion()\n",
    "\n",
    "        if self.args.use_amp:\n",
    "            scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "        for epoch in range(self.args.train_epochs):\n",
    "            iter_count = 0\n",
    "            train_loss = []\n",
    "            \n",
    "            self.model.train()\n",
    "            epoch_time = time.time()\n",
    "            for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(train_loader):\n",
    "                iter_count += 1\n",
    "                \n",
    "                model_optim.zero_grad()\n",
    "                pred, true = self._process_one_batch(\n",
    "                    train_data, batch_x, batch_y, batch_x_mark, batch_y_mark)\n",
    "                print(pred)\n",
    "                loss = criterion(pred, true)\n",
    "                train_loss.append(loss.item())\n",
    "                \n",
    "                if (i+1) % 100==0:\n",
    "                    print(\"\\titers: {0}, epoch: {1} | loss: {2:.7f}\".format(i + 1, epoch + 1, loss.item()))\n",
    "                    speed = (time.time()-time_now)/iter_count\n",
    "                    left_time = speed*((self.args.train_epochs - epoch)*train_steps - i)\n",
    "                    print('\\tspeed: {:.4f}s/iter; left time: {:.4f}s'.format(speed, left_time))\n",
    "                    iter_count = 0\n",
    "                    time_now = time.time()\n",
    "                \n",
    "                if self.args.use_amp:\n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.step(model_optim)\n",
    "                    scaler.update()\n",
    "                else:\n",
    "                    loss.backward()\n",
    "                    model_optim.step()\n",
    "\n",
    "            print(\"Epoch: {} cost time: {}\".format(epoch+1, time.time()-epoch_time))\n",
    "            train_loss = np.average(train_loss)\n",
    "            vali_loss = self.vali(vali_data, vali_loader, criterion)\n",
    "            test_loss = self.vali(test_data, test_loader, criterion)\n",
    "\n",
    "            print(\"Epoch: {0}, Steps: {1} | Train Loss: {2:.7f} Vali Loss: {3:.7f} Test Loss: {4:.7f}\".format(\n",
    "                epoch + 1, train_steps, train_loss, vali_loss, test_loss))\n",
    "            early_stopping(vali_loss, self.model, path)\n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "\n",
    "            adjust_learning_rate(model_optim, epoch+1, self.args)\n",
    "            \n",
    "        best_model_path = path+'/'+'checkpoint.pth'\n",
    "        self.model.load_state_dict(torch.load(best_model_path))\n",
    "        \n",
    "        return self.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_data() missing 1 required positional argument: 'args'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[290], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m vali_data, vali_loader \u001b[39m=\u001b[39m get_data(flag \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mval\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: get_data() missing 1 required positional argument: 'args'"
     ]
    }
   ],
   "source": [
    "vali_data, vali_loader = get_data(flag = 'val')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GIG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
